{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial ML System - Data Pipeline\n",
    "\n",
    "Version: 1.0.0\n",
    "\n",
    "This notebook handles data ingestion, validation, and initial processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PROJECT_ROOT = Path('/content/financial-ml-system')\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.utils.constants import DATA_DIR, TRADING_DAYS_PER_YEAR\n",
    "from src.utils.config_loader import config\n",
    "from src.utils.helpers import calculate_returns, calculate_sharpe_ratio, calculate_max_drawdown\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFetcher:\n",
    "    \"\"\"Fetch market data from Yahoo Finance.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: Path = None):\n",
    "        self.cache_dir = cache_dir or DATA_DIR / 'raw'\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def fetch(self, ticker: str, start_date: str, end_date: str = None) -> pd.DataFrame:\n",
    "        \"\"\"Fetch OHLCV data for a ticker.\"\"\"\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        cache_file = self.cache_dir / f\"{ticker}_{start_date}_{end_date}.csv\"\n",
    "        \n",
    "        if cache_file.exists():\n",
    "            print(f\"Loading cached data for {ticker}\")\n",
    "            return pd.read_csv(cache_file, index_col=0, parse_dates=True)\n",
    "        \n",
    "        print(f\"Fetching data for {ticker} from {start_date} to {end_date}\")\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        if data.empty:\n",
    "            raise ValueError(f\"No data returned for {ticker}\")\n",
    "        \n",
    "        data.to_csv(cache_file)\n",
    "        print(f\"Cached data to {cache_file}\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def fetch_multiple(self, tickers: list, start_date: str, end_date: str = None) -> dict:\n",
    "        \"\"\"Fetch data for multiple tickers.\"\"\"\n",
    "        return {ticker: self.fetch(ticker, start_date, end_date) for ticker in tickers}\n",
    "\n",
    "print(\"DataFetcher class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Validation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidator:\n",
    "    \"\"\"Validate market data quality.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate(data: pd.DataFrame) -> dict:\n",
    "        \"\"\"Run validation checks on market data.\"\"\"\n",
    "        results = {\n",
    "            'missing_values': data.isnull().sum().to_dict(),\n",
    "            'total_rows': len(data),\n",
    "            'date_range': (data.index.min(), data.index.max()),\n",
    "            'negative_prices': (data[['Open', 'High', 'Low', 'Close']] < 0).sum().to_dict(),\n",
    "            'zero_volume': (data['Volume'] == 0).sum(),\n",
    "            'high_low_check': (data['High'] < data['Low']).sum(),\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_validation_report(results: dict):\n",
    "        \"\"\"Print validation results.\"\"\"\n",
    "        print(\"Data Validation Report\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Total Rows: {results['total_rows']}\")\n",
    "        print(f\"Date Range: {results['date_range'][0]} to {results['date_range'][1]}\")\n",
    "        print(f\"\\nMissing Values:\")\n",
    "        for col, count in results['missing_values'].items():\n",
    "            if count > 0:\n",
    "                print(f\"  {col}: {count}\")\n",
    "        print(f\"\\nZero Volume Days: {results['zero_volume']}\")\n",
    "        print(f\"High < Low Issues: {results['high_low_check']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "print(\"DataValidator class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner:\n",
    "    \"\"\"Clean and prepare market data.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean(data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Clean market data.\"\"\"\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Forward fill missing values\n",
    "        df = df.fillna(method='ffill')\n",
    "        \n",
    "        # Remove any remaining NaN rows\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Ensure positive prices\n",
    "        price_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "        for col in price_cols:\n",
    "            if col in df.columns:\n",
    "                df = df[df[col] > 0]\n",
    "        \n",
    "        # Sort by date\n",
    "        df = df.sort_index()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_basic_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add basic derived features.\"\"\"\n",
    "        df = data.copy()\n",
    "        \n",
    "        # Daily returns\n",
    "        df['Returns'] = df['Close'].pct_change()\n",
    "        \n",
    "        # Log returns\n",
    "        df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "        \n",
    "        # Price range\n",
    "        df['Range'] = df['High'] - df['Low']\n",
    "        df['Range_Pct'] = df['Range'] / df['Close']\n",
    "        \n",
    "        # Gap\n",
    "        df['Gap'] = df['Open'] - df['Close'].shift(1)\n",
    "        df['Gap_Pct'] = df['Gap'] / df['Close'].shift(1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "print(\"DataCleaner class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "ticker = config.get('data.default_ticker', 'SPY')\n",
    "start_date = config.get('data.start_date', '2018-01-01')\n",
    "\n",
    "# Fetch data\n",
    "fetcher = DataFetcher()\n",
    "raw_data = fetcher.fetch(ticker, start_date)\n",
    "\n",
    "print(f\"\\nFetched {len(raw_data)} rows\")\n",
    "print(f\"Columns: {list(raw_data.columns)}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = DataValidator()\n",
    "validation_results = validator.validate(raw_data)\n",
    "validator.print_validation_report(validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = DataCleaner()\n",
    "cleaned_data = cleaner.clean(raw_data)\n",
    "cleaned_data = cleaner.add_basic_features(cleaned_data)\n",
    "\n",
    "print(f\"Cleaned data: {len(cleaned_data)} rows\")\n",
    "print(f\"Columns: {list(cleaned_data.columns)}\")\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Summary Statistics\")\n",
    "print(\"=\"*50)\n",
    "print(cleaned_data[['Open', 'High', 'Low', 'Close', 'Volume']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price chart\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Close price\n",
    "axes[0].plot(cleaned_data.index, cleaned_data['Close'], label='Close Price', linewidth=1)\n",
    "axes[0].set_title(f'{ticker} Price History', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Volume\n",
    "axes[1].bar(cleaned_data.index, cleaned_data['Volume'], alpha=0.5, label='Volume')\n",
    "axes[1].set_title('Trading Volume', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Volume')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATA_DIR.parent / 'results' / 'price_volume_chart.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Chart saved to results/price_volume_chart.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Returns histogram\n",
    "axes[0].hist(cleaned_data['Returns'].dropna(), bins=100, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Daily Returns Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Returns')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(cleaned_data['Returns'].dropna(), dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot (Returns vs Normal)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATA_DIR.parent / 'results' / 'returns_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Chart saved to results/returns_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "returns = cleaned_data['Returns'].dropna()\n",
    "\n",
    "metrics = {\n",
    "    'Total Return': (cleaned_data['Close'].iloc[-1] / cleaned_data['Close'].iloc[0] - 1) * 100,\n",
    "    'Annualized Return': returns.mean() * TRADING_DAYS_PER_YEAR * 100,\n",
    "    'Annualized Volatility': returns.std() * np.sqrt(TRADING_DAYS_PER_YEAR) * 100,\n",
    "    'Sharpe Ratio': calculate_sharpe_ratio(returns),\n",
    "    'Max Drawdown': calculate_max_drawdown(cleaned_data['Close']) * 100,\n",
    "    'Positive Days': (returns > 0).sum() / len(returns) * 100,\n",
    "    'Negative Days': (returns < 0).sum() / len(returns) * 100,\n",
    "}\n",
    "\n",
    "print(\"\\nPerformance Metrics\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric:<25} {value:>10.2f}{'%' if 'Return' in metric or 'Days' in metric or 'Drawdown' in metric or 'Volatility' in metric else ''}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to processed data directory\n",
    "processed_dir = DATA_DIR / 'processed'\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = processed_dir / f\"{ticker}_processed.csv\"\n",
    "cleaned_data.to_csv(output_file)\n",
    "\n",
    "print(f\"Processed data saved to: {output_file}\")\n",
    "print(f\"Shape: {cleaned_data.shape}\")\n",
    "print(f\"Date range: {cleaned_data.index.min()} to {cleaned_data.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Create Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data module to src/data/\n",
    "data_module_code = '''\"\"\"Data ingestion and processing module.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "class DataFetcher:\n",
    "    \"\"\"Fetch market data from Yahoo Finance.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: Path = None):\n",
    "        self.cache_dir = cache_dir\n",
    "        if cache_dir:\n",
    "            self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def fetch(self, ticker: str, start_date: str, end_date: str = None) -> pd.DataFrame:\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        if self.cache_dir:\n",
    "            cache_file = self.cache_dir / f\"{ticker}_{start_date}_{end_date}.csv\"\n",
    "            if cache_file.exists():\n",
    "                return pd.read_csv(cache_file, index_col=0, parse_dates=True)\n",
    "        \n",
    "        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        if data.empty:\n",
    "            raise ValueError(f\"No data returned for {ticker}\")\n",
    "        \n",
    "        if self.cache_dir:\n",
    "            data.to_csv(cache_file)\n",
    "        \n",
    "        return data\n",
    "\n",
    "class DataCleaner:\n",
    "    \"\"\"Clean and prepare market data.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean(data: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = data.copy()\n",
    "        df = df.fillna(method='ffill').dropna()\n",
    "        \n",
    "        price_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "        for col in price_cols:\n",
    "            if col in df.columns:\n",
    "                df = df[df[col] > 0]\n",
    "        \n",
    "        return df.sort_index()\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_basic_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = data.copy()\n",
    "        df['Returns'] = df['Close'].pct_change()\n",
    "        df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "        df['Range'] = df['High'] - df['Low']\n",
    "        df['Range_Pct'] = df['Range'] / df['Close']\n",
    "        return df\n",
    "'''\n",
    "\n",
    "with open(PROJECT_ROOT / 'src' / 'data' / 'ingestion.py', 'w') as f:\n",
    "    f.write(data_module_code)\n",
    "\n",
    "print(\"Created: src/data/ingestion.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline Complete\n",
    "\n",
    "Next: Open `02_feature_engineering.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
