{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial ML System - SVM Training\n",
    "\n",
    "This notebook trains the SVM classifier for market regime detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PROJECT_ROOT = Path('/content/financial-ml-system')\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.utils.constants import DATA_DIR, MODELS_DIR, REGIME_NAMES\n",
    "from src.utils.config_loader import config\n",
    "from src.utils.helpers import time_series_split\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = config.get('data.default_ticker', 'SPY')\n",
    "features_file = DATA_DIR / 'processed' / f\"{ticker}_features.csv\"\n",
    "\n",
    "if not features_file.exists():\n",
    "    raise FileNotFoundError(f\"Run 02_feature_engineering.ipynb first\")\n",
    "\n",
    "data = pd.read_csv(features_file, index_col=0, parse_dates=True)\n",
    "print(f\"Loaded {len(data)} rows with {len(data.columns)} columns\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for SVM\n",
    "feature_cols = [\n",
    "    'SMA_Ratio_5', 'SMA_Ratio_20', 'SMA_Ratio_50',\n",
    "    'RSI', 'MACD', 'MACD_Hist',\n",
    "    'BB_Width', 'BB_Position',\n",
    "    'ATR_Pct', 'Volatility',\n",
    "    'Volume_Ratio', 'ROC'\n",
    "]\n",
    "\n",
    "# Check if all features exist\n",
    "missing = [col for col in feature_cols if col not in data.columns]\n",
    "if missing:\n",
    "    print(f\"Warning: Missing features: {missing}\")\n",
    "    feature_cols = [col for col in feature_cols if col in data.columns]\n",
    "\n",
    "X = data[feature_cols].values\n",
    "y = data['Regime'].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "for regime, name in REGIME_NAMES.items():\n",
    "    count = (y == regime).sum()\n",
    "    print(f\"{name}: {count} ({count/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series split\n",
    "train_size = config.get('data.train_test_split', 0.8)\n",
    "split_idx = int(len(X) * train_size)\n",
    "\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining date range: {data.index[0]} to {data.index[split_idx-1]}\")\n",
    "print(f\"Test date range: {data.index[split_idx]} to {data.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled\")\n",
    "print(f\"Training set mean: {X_train_scaled.mean():.4f}\")\n",
    "print(f\"Training set std: {X_train_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'C': config.get('models.svm.C_options', [0.1, 1, 10, 100]),\n",
    "    'kernel': config.get('models.svm.kernel_options', ['rbf', 'poly', 'linear']),\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "print(\"Parameter grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Time series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=config.get('models.svm.cv_folds', 5))\n",
    "\n",
    "# Grid search\n",
    "print(\"\\nStarting grid search...\")\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(random_state=42),\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nBest parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest cross-validation score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# Training accuracy\n",
    "train_pred = best_svm.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "\n",
    "# Test accuracy\n",
    "test_pred = best_svm.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report (Test Set):\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, test_pred, target_names=list(REGIME_NAMES.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=list(REGIME_NAMES.values()),\n",
    "            yticklabels=list(REGIME_NAMES.values()))\n",
    "ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('True Label')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'svm_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction confidence\n",
    "test_proba = best_svm.decision_function(X_test_scaled)\n",
    "test_confidence = np.max(test_proba, axis=1) if len(test_proba.shape) > 1 else np.abs(test_proba)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(test_confidence, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.set_title('SVM Prediction Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Confidence Score')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'svm_confidence.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean confidence: {test_confidence.mean():.4f}\")\n",
    "print(f\"Std confidence: {test_confidence.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Linear Kernel Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search.best_params_['kernel'] == 'linear':\n",
    "    # Get feature importance from linear kernel\n",
    "    importance = np.abs(best_svm.coef_).mean(axis=0)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    ax.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "    ax.set_title('Feature Importance (Linear SVM)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Importance')\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PROJECT_ROOT / 'results' / 'svm_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 5 features:\")\n",
    "    print(feature_importance.head())\n",
    "else:\n",
    "    print(f\"Feature importance not available for {grid_search.best_params_['kernel']} kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save SVM model\n",
    "model_dir = MODELS_DIR / 'svm'\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "svm_path = model_dir / 'svm_classifier.pkl'\n",
    "scaler_path = model_dir / 'scaler.pkl'\n",
    "\n",
    "joblib.dump(best_svm, svm_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Save feature names\n",
    "feature_info = {\n",
    "    'feature_names': feature_cols,\n",
    "    'train_accuracy': float(train_accuracy),\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'best_params': grid_search.best_params_\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(model_dir / 'model_info.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2)\n",
    "\n",
    "print(f\"Model saved to: {svm_path}\")\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n",
    "print(f\"Model info saved to: {model_dir / 'model_info.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Create SVM Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save SVM module\n",
    "svm_module = '''\"\"\"SVM classifier module.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "\n",
    "class SVMRegimeClassifier:\n",
    "    \"\"\"SVM-based market regime classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: Path = None):\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        if model_path:\n",
    "            self.load(model_path)\n",
    "    \n",
    "    def train(self, X, y, param_grid=None):\n",
    "        \"\"\"Train SVM classifier.\"\"\"\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        if param_grid:\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "            grid_search = GridSearchCV(SVC(random_state=42), param_grid, \n",
    "                                      cv=tscv, n_jobs=-1)\n",
    "            grid_search.fit(X_scaled, y)\n",
    "            self.model = grid_search.best_estimator_\n",
    "        else:\n",
    "            self.model = SVC(random_state=42)\n",
    "            self.model.fit(X_scaled, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict regime.\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict regime probabilities.\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.decision_function(X_scaled)\n",
    "    \n",
    "    def save(self, path: Path):\n",
    "        \"\"\"Save model.\"\"\"\n",
    "        joblib.dump(self.model, path / 'svm_classifier.pkl')\n",
    "        joblib.dump(self.scaler, path / 'scaler.pkl')\n",
    "    \n",
    "    def load(self, path: Path):\n",
    "        \"\"\"Load model.\"\"\"\n",
    "        self.model = joblib.load(path / 'svm_classifier.pkl')\n",
    "        self.scaler = joblib.load(path / 'scaler.pkl')\n",
    "'''\n",
    "\n",
    "with open(PROJECT_ROOT / 'src' / 'models' / 'svm_classifier.py', 'w') as f:\n",
    "    f.write(svm_module)\n",
    "\n",
    "print(\"Created: src/models/svm_classifier.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Training Complete\n",
    "\n",
    "Next: Open `04_nn_training.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
