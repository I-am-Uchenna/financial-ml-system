{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial ML System - Neural Network Training\n",
    "\n",
    "This notebook trains the neural network for return prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "PROJECT_ROOT = Path('/content/financial-ml-system')\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.utils.constants import DATA_DIR, MODELS_DIR\n",
    "from src.utils.config_loader import config\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = config.get('data.default_ticker', 'SPY')\n",
    "features_file = DATA_DIR / 'processed' / f\"{ticker}_features.csv\"\n",
    "\n",
    "data = pd.read_csv(features_file, index_col=0, parse_dates=True)\n",
    "print(f\"Loaded {len(data)} rows\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "feature_cols = [\n",
    "    'Returns', 'SMA_Ratio_5', 'SMA_Ratio_20', 'SMA_Ratio_50',\n",
    "    'RSI', 'MACD', 'MACD_Hist',\n",
    "    'BB_Width', 'BB_Position',\n",
    "    'ATR_Pct', 'Volatility',\n",
    "    'Volume_Ratio', 'ROC', 'Momentum'\n",
    "]\n",
    "\n",
    "missing = [col for col in feature_cols if col not in data.columns]\n",
    "if missing:\n",
    "    print(f\"Warning: Missing features: {missing}\")\n",
    "    feature_cols = [col for col in feature_cols if col in data.columns]\n",
    "\n",
    "# Create target: next period return\n",
    "data['Target'] = data['Returns'].shift(-1)\n",
    "data = data.dropna(subset=['Target'])\n",
    "\n",
    "X = data[feature_cols].values\n",
    "y = data['Target'].values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target mean: {y.mean():.6f}\")\n",
    "print(f\"Target std: {y.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = config.get('data.train_test_split', 0.8)\n",
    "split_idx = int(len(X) * train_size)\n",
    "\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled to [0, 1]\")\n",
    "print(f\"Training set min: {X_train_scaled.min():.4f}\")\n",
    "print(f\"Training set max: {X_train_scaled.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, layers_config, dropout_rates, learning_rate):\n",
    "    \"\"\"Build neural network model.\"\"\"\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    \n",
    "    # Hidden layers\n",
    "    for neurons, dropout in zip(layers_config, dropout_rates):\n",
    "        model.add(layers.Dense(neurons, activation='relu'))\n",
    "        if dropout > 0:\n",
    "            model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Get configuration\n",
    "layers_config = config.get('models.nn.layers', [64, 32, 16])\n",
    "dropout_rates = config.get('models.nn.dropout', [0.3, 0.2, 0.0])\n",
    "learning_rate = config.get('models.nn.learning_rate', 0.001)\n",
    "\n",
    "# Build model\n",
    "model = build_model(\n",
    "    input_dim=X_train_scaled.shape[1],\n",
    "    layers_config=layers_config,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=config.get('models.nn.early_stopping_patience', 10),\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=config.get('models.nn.epochs', 100),\n",
    "    batch_size=config.get('models.nn.batch_size', 32),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "ax1.plot(history.history['loss'], label='Training Loss')\n",
    "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax1.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss (MSE)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "ax2.plot(history.history['mae'], label='Training MAE')\n",
    "ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
    "ax2.set_title('Model MAE', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'nn_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "train_pred = model.predict(X_train_scaled, verbose=0).flatten()\n",
    "test_pred = model.predict(X_test_scaled, verbose=0).flatten()\n",
    "\n",
    "# Metrics\n",
    "train_mae = mean_absolute_error(y_train, train_pred)\n",
    "train_mse = mean_squared_error(y_train, train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "test_mae = mean_absolute_error(y_test, test_pred)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(\"Performance Metrics\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training MAE:  {train_mae:.6f}\")\n",
    "print(f\"Training RMSE: {train_rmse:.6f}\")\n",
    "print(f\"Test MAE:      {test_mae:.6f}\")\n",
    "print(f\"Test RMSE:     {test_rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directional accuracy\n",
    "train_direction = np.sign(train_pred) == np.sign(y_train)\n",
    "test_direction = np.sign(test_pred) == np.sign(y_test)\n",
    "\n",
    "print(\"\\nDirectional Accuracy\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training: {train_direction.mean():.4f}\")\n",
    "print(f\"Test:     {test_direction.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "ax1.scatter(y_test, test_pred, alpha=0.5, s=10)\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "ax1.set_title('Predicted vs Actual Returns', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Actual Returns')\n",
    "ax1.set_ylabel('Predicted Returns')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Error distribution\n",
    "errors = test_pred - y_test\n",
    "ax2.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "ax2.set_title('Prediction Error Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Prediction Error')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'nn_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "\n",
    "# Save neural network\n",
    "model_dir = MODELS_DIR / 'nn'\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = model_dir / 'nn_predictor.h5'\n",
    "scaler_path = model_dir / 'scaler.pkl'\n",
    "\n",
    "model.save(model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'feature_names': feature_cols,\n",
    "    'train_mae': float(train_mae),\n",
    "    'test_mae': float(test_mae),\n",
    "    'train_rmse': float(train_rmse),\n",
    "    'test_rmse': float(test_rmse),\n",
    "    'train_direction_acc': float(train_direction.mean()),\n",
    "    'test_direction_acc': float(test_direction.mean()),\n",
    "    'architecture': {\n",
    "        'layers': layers_config,\n",
    "        'dropout': dropout_rates,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(model_dir / 'model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n",
    "print(f\"Model info saved to: {model_dir / 'model_info.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training Complete\n",
    "\n",
    "Next: Open `05_signal_generation.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
